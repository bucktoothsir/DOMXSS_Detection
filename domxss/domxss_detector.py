#! /usr/bin/env python3
# -*- coding: utf-8 -*-
# vim:fenc=utf-8
#
# Copyright Â©  2021-12-01 22:16 bucktoothsir <rsliu.xd@gmail.com>
#
# Distributed under terms of the MIT license.

import re
import time
from bs4 import BeautifulSoup, SoupStrainer
from urllib.parse import urljoin
from selenium.common import exceptions
from webdriver import WebDriver
from .domxss_alert_info import DomAlertInfo
from .domxss_detector_config import UNLIKELY_STR, ATTACK_VECTORS, RE_DOMXSS_SINKS, RE_DOMXSS_SOURCES, SEPERATOR




class DomXSSDetector():
    """DomXSS Detector based on static methods.
    (1) scan by payload.
    (2) scan by regular regression.

    Attributes:
        webdriver: A webdriver object, interacting with the browser.
       _unlikely_str: A string.
            eg: if the payload is <script>alert(42)</script>, then _unlikely_str='42'.
            which is used to check if the popup is generated by the payload we send.
        _attack_vecotrs: A list of default attack vectors.
    """

    def __init__(self, browser='firefox'):
        self.webdriver = WebDriver(browser)
        self._unlikely_str = UNLIKELY_STR
        self._attack_vecotrs = ATTACK_VECTORS

    def _alert_helper(self, url, attack_vector, tag_name='', attribute_id='', attribute_name=''):
        """Check if the popup is generated by the DomXSS attack. 
        """
        alert_text = self.webdriver.get_alert_text()
        if alert_text == self._unlikely_str:
            dom_alert_info = DomAlertInfo(
                url, attack_vector, tag_name=tag_name, attribute_id=attribute_id, attribute_name=attribute_name)
            return dom_alert_info
        else:
            return None

    def _payload_scan_helper(self, url, attack_vector):
        """Scan by payload.
        (1) Get the url, check if there is a popup and if the popup is generated by attack_vector.
        (2) Attack 'input' tags, check popup.
        (3) Attack 'div' tags, check popup.
        Args:
            url: str, the concatenation of the url of website and attack vector.
                eg: https://www.google.com#<script>alert('42')</script>
            attack_vector: str.

        Returns:
            if the website is vulnerable, return dom_alert_info.
            else, return None.
        """
        try:
            self.webdriver.get(url)
            time.sleep(1)
        except exceptions.UnexpectedAlertPresentException:
            pass
        finally:
            dom_alert_info = self._alert_helper(url, attack_vector)
            if dom_alert_info:
                return dom_alert_info

        possible_domxss_triggers = list()
        try:
            input_elements = self.webdriver.find_tag('input')
            if input_elements:
                possible_domxss_triggers.extend(input_elements)
            buttion_elements = self.webdriver.find_tag('button')
            if buttion_elements:
                possible_domxss_triggers.extend(buttion_elements)
        except exceptions.UnexpectedAlertPresentException:
            pass
        finally:
            dom_alert_info = self._alert_helper(url, attack_vector)
            self.vulnerable = True
            if dom_alert_info:
                return dom_alert_info

        for i in range(len(possible_domxss_triggers)):
            if i >= len(possible_domxss_triggers):
                break
            possible_domxss_trigger = possible_domxss_triggers[i]
            tag_name = ''
            attribute_id = ''
            attribute_name = ''
            try:
                tag_name = possible_domxss_trigger.tag_name
                attribute_id = possible_domxss_trigger.get_attribute('id')
                attribute_name = possible_domxss_trigger.get_attribute('name')
            except:
                pass
            try:
                if tag_name == 'input':
                    possible_domxss_trigger.send_keys(attack_vector)
                possible_domxss_trigger.click()
            except (exceptions.StaleElementReferenceException, exceptions.ElementNotInteractableException, exceptions.ElementClickInterceptedException, exceptions.UnexpectedAlertPresentException):
                pass
            finally:
                dom_alert_info = self._alert_helper(
                    url, attack_vector, tag_name=tag_name, attribute_id=attribute_id, attribute_name=attribute_name)
                if dom_alert_info:
                    return dom_alert_info

            try:
                self.webdriver.get(url)
            except exceptions.UnexpectedAlertPresentException:
                pass
            finally:
                dom_alert_info = self._alert_helper(
                    url, attack_vector, tag_name=tag_name, attribute_id=attribute_id, attribute_name=attribute_name)
                if dom_alert_info:
                    return dom_alert_info

            try:
                input_elements = self.webdriver.find_tag('input')
                if input_elements:
                    possible_domxss_triggers = []
                    possible_domxss_triggers.extend(input_elements)
                button_elements = self.webdriver.find_tag('button')
                if buttion_elements:
                    possible_domxss_triggers.extend(button_elements)
            except exceptions.UnexpectedAlertPresentException:
                pass
            finally:
                dom_alert_info = self._alert_helper(
                    url, attack_vector, tag_name=tag_name, attribute_id=attribute_id, attribute_name=attribute_name)
                if dom_alert_info:
                    return dom_alert_info

        try:
            all_elements = self.webdriver.find_tag('div')
        except exceptions.UnexpectedAlertPresentException:
            pass
        finally:
            dom_alert_info = self._alert_helper(
                url, attack_vector)
            if dom_alert_info:
                return dom_alert_info

        for i in range(len(all_elements)):
            if i >= len(all_elements):
                break
            element = all_elements[i]
            tag_name = ''
            attribute_id = ''
            attribute_name = ''
            try:
                tag_name = element.tag_name
                attribute_id = element.get_attribute('id')
                attribute_name = element.get_attribute('name')
            except:
                pass
            try:
                element.click()
            except (exceptions.ElementClickInterceptedException, exceptions.ElementNotInteractableException, exceptions.StaleElementReferenceException, exceptions.UnexpectedAlertPresentException):
                pass
            finally:
                dom_alert_info = self._alert_helper(
                    url, attack_vector, tag_name=tag_name, attribute_id=attribute_id, attribute_name=attribute_name)
                if dom_alert_info:
                    return dom_alert_info
            try:
                self.webdriver.get(url)
            except exceptions.UnexpectedAlertPresentException:
                pass
            finally:
                dom_alert_info = self._alert_helper(
                    url, attack_vector, tag_name=tag_name, attribute_id=attribute_id, attribute_name=attribute_name)
                if dom_alert_info:
                    return dom_alert_info

            try:
                possible_all_elements = self.webdriver.find_tag('div')
                if possible_all_elements:
                    all_elements = possible_all_elements
            except exceptions.UnexpectedAlertPresentException:
                pass
            finally:
                dom_alert_info = self._alert_helper(
                    url, attack_vector, tag_name=tag_name, attribute_id=attribute_id, attribute_name=attribute_name)
                if dom_alert_info:
                    return dom_alert_info
        return None

    def scan_by_payload(self, url, attack_vecotrs=list()):
        """Scan by payload, can be called externally.

        Args:
            url: str, url of the webiste you want to attack.
                eg: https://www.google.com
            attack_vecotrs: 
                Optional, list of attack_vecotrs.
                If attack_vecotrs is not None, the url will be attacked by payloads in attack_vecotrs.
                Otherwise, the default attack vectors will be used.

        Returns:
            bool: If the website is vulnerable, return True.
            str: Scan result in detail. If the website is not vulnerable, return ''.
        """
        if not attack_vecotrs:
            attack_vecotrs = self._attack_vecotrs
        for i, attack_vector in enumerate(attack_vecotrs):
            print('Scan by %d attack_vecotr: %s' % (i+1, attack_vector))
            url += attack_vector
            result = self._payload_scan_helper(url, attack_vector)
            if result:
                tag_name = result.get_tag_name()
                scan_info = ''
                if tag_name:
                    scan_info = 'Tag name: %s, Att name: %s, Att id: %s' % (
                        tag_name, result.get_attribute_name, result.get_attribute_id)
                return True, scan_info
        else:
            return False, ''

    def _get_domxss_log_helper(self, html, regex):
        """Generate log file for DOMXSS detail information
        (1) Count the number of tags matached between input html content and regex
        (2) Provide the detail information about the potential malicious tags including tag name and location
        Args:
            html: str, the HTML content parsed from URL
            regex: the regular expression used to compare with the tags in html content
        Returns:
            str: The detail informaion of potential DOMXSS
        """
        try:
            count = [{'pos_start': match.start(),'pos_end':match.end(), 'match':match.group(0)}
                for match in regex.finditer(html)]
        except exceptions.UnexpectedAlertPresentException:
            pass
        finally:
            log_detail = 'Number of found: ' + str(len(count)) + '\n' + SEPERATOR
            for match in regex.finditer(html):
                start = match.start()
                end = match.end()
                detail_info = '< ' + html[start:end] + ', ' + str(start) + ':' + str(end) + ' >'
                log_detail = log_detail+ detail_info
            return log_detail

    def scan_by_reg(self, url, outfile):
        """Scan by regular expression.
        (1) Get the HTML content parsed from the input URL
        (2) Crawl the scripts by using BeautifulSoup
        (3) Invoking _get_domxss_log_helper(...) to scan both the surface level and source level
        Args:
            url: str, the concatenation of the url of website and attack vector.
                eg: https://www.google.com#<script>alert('42')</script>
            outfile: str, the filename that stores the scan results.
        """
        surface_html = self.webdriver.get_html(url)
        all_script_urls = []
        legit_script_urls = []
        scripts_code = BeautifulSoup(surface_html, 'html.parser', parse_only=SoupStrainer('script'))
        for tag in scripts_code: 
            if tag.has_attr('src'): 
                src_url = tag['src']                      
                src_url = urljoin(str(url), str(src_url))
                all_script_urls.append(src_url)
        for script_url in all_script_urls:
            if(script_url[0:4] == 'http'):
                legit_script_urls.append(script_url)

        with open(outfile, 'w+') as f:
            f.write('This log is for the detail information of the detection result.\n' + 'The information format is <Potential vunlerable tag + Location in the text>\n\n\n')
            f.write('\n\nSourses for URL: ' + url + '\n')
            f.write(self._get_domxss_log_helper(surface_html, re.compile(RE_DOMXSS_SOURCES)))
            f.write('\n\nSinks for URL: ' + url + '\n')
            f.write(self._get_domxss_log_helper(surface_html, re.compile(RE_DOMXSS_SINKS)))
            for http_url in legit_script_urls:
                src_html = self.webdriver.get_html(url)               
                f.write('\n\nSourses for URL: ' + http_url + '\n' )
                f.write(self._get_domxss_log_helper(src_html, re.compile(RE_DOMXSS_SOURCES)))
                f.write('\n\nSinks for URL: ' + http_url + '\n')
                f.write(self._get_domxss_log_helper(src_html, re.compile(RE_DOMXSS_SINKS)))
        
